{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hw9533\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"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\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-generation\", model=\"meta-llama/Llama-3.2-1B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To solve this problem, let's first identify the odd numbers in the given group:\n",
      "\n",
      "1. 15\n",
      "2. 5\n",
      "3. 13\n",
      "4. 7\n",
      "5. 1\n",
      "\n",
      "Now, let's add these odd numbers:\n",
      "\n",
      "15 + 5 = 20\n",
      "20 + 13 = 33\n",
      "33 + 7 = 40\n",
      "40 + 1 = 41\n",
      "\n",
      "The sum of the odd numbers is 41, which is an odd number.\n",
      "\n",
      "Since the sum is odd, we need to identify the even number that was supposed to be added to the sum. In this case, the odd number 41 is the result of the addition. \n",
      "\n",
      "The result is an odd number, so we need to find the even number that was supposed to be added to the sum.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reasoning\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": '''\n",
    "    The odd numbers in this group add up to an even number: 15,\n",
    "    32, 5, 13, 82, 7, 1.\n",
    "    Solve by breaking the problem into steps. First, identify\n",
    "    the odd numbers, add them, and indicate whether the result\n",
    "    is odd or even.\n",
    "    '''}\n",
    "]\n",
    "\n",
    "response = pipe(messages, max_new_tokens=1000)  # Adjust the token length as needed\n",
    "print(response[0]['generated_text'][1]['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history of artificial intelligence (AI) spans several decades, with significant advancements and milestones in various fields. Here's a brief overview:\n",
      "\n",
      "**Early Beginnings (1950s-1960s)**\n",
      "\n",
      "1. **Alan Turing's Paper (1950)**: Turing proposed the Turing Test, a measure of a machine's ability to exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human.\n",
      "2. **First AI Program (1956)**: The Logical Theorist, a computer program designed to simulate human reasoning, was developed by Allen Newell and Herbert Simon.\n",
      "3. **ELIZA (1966)**: ELIZA, a chatbot developed by Joseph Weizenbaum, was the first AI program to simulate a conversation with a human.\n",
      "\n",
      "**Rule-Based Systems (1970s)**\n",
      "\n",
      "1. **MYCIN (1976)**: MYCIN, a rule-based expert system developed at Stanford University, was the first AI system to use a knowledge base and inference rules.\n",
      "2. **ELIZA 2.0 (1976)**: ELIZA 2.0, an improved version of the original chatbot, was developed by Joseph Weizenbaum.\n",
      "\n",
      "**Machine Learning (1980s)**\n",
      "\n",
      "1. **Perceptron (1957)**: The Perceptron, a type of feedforward neural network, was the first AI algorithm to learn from experience.\n",
      "2. **Backpropagation (1986)**: David Rumelhart, Geoffrey Hinton, and Ronald Williams developed backpropagation, a key algorithm in neural networks.\n",
      "3. **Neural Networks (1983)**: David Rumelhart, Geoffrey Hinton, and Ronald Williams developed the backpropagation algorithm, which is still used in neural networks today.\n",
      "\n",
      "**Advances in Deep Learning (1990s-2000s)**\n",
      "\n",
      "1. **Backpropagation with Backpropagation (1995)**: The authors of the paper \"Backpropagation with Backpropagation\" improved the backpropagation algorithm, which led to significant improvements in neural networks.\n",
      "2. **Convolutional Neural Networks (2006)**: AlexNet, a convolutional neural network, was developed at Google, which won the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in 2012.\n",
      "3. **Deep Learning (2006)**: The development of deep learning algorithms, such as recurrent neural networks (RNNs) and long short-term memory (LSTM) networks, led to significant advancements in AI.\n",
      "\n",
      "**Modern AI (2010s-present)**\n",
      "\n",
      "1. **Deep Learning Frameworks (2010s)**: The development of deep learning frameworks, such as TensorFlow and PyTorch, made it easier to build and train AI models.\n",
      "2. **Computer Vision (2010s)**: The development of computer vision algorithms, such as object detection and segmentation, enabled AI systems to recognize and understand visual data.\n",
      "3. **Natural Language Processing (2010s)**: The development of natural language processing (NLP) algorithms, such as language translation and sentiment analysis, enabled AI systems to understand and generate human language.\n",
      "\n",
      "Today, AI is a rapidly evolving field, with significant advancements in areas such as:\n",
      "\n",
      "* **Computer Vision**: AI systems can recognize and understand visual data from images and videos.\n",
      "* **Natural Language Processing**: AI systems can understand and generate human language, including speech recognition and text analysis.\n",
      "* **Robotics**: AI systems can control and interact with physical robots, enabling them to perform tasks autonomously.\n",
      "* **Predictive Maintenance**: AI systems can predict and prevent equipment failures, reducing downtime and increasing efficiency.\n",
      "\n",
      "The history of artificial intelligence is a story of continuous innovation and improvement, with significant advancements in various fields. As AI continues to evolve, we can expect to see even more exciting developments in the years to come.\n"
     ]
    }
   ],
   "source": [
    "# Part_2\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": '''\n",
    "    The history of artificial intellligence is\n",
    "    '''}\n",
    "]\n",
    "\n",
    "response = pipe(messages, max_new_tokens=1000)  # Adjust the token length as needed\n",
    "print(response[0]['generated_text'][1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hw9533\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hw9533\\.cache\\huggingface\\hub\\models--meta-llama--Llama-3.2-3B-Instruct. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading shards: 100%|██████████| 2/2 [00:55<00:00, 27.85s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.90s/it]\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "Lipe = pipeline(\"text-generation\", model=\"meta-llama/Llama-3.2-3B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antibiotics are medications that target bacterial infections by either killing or preventing bacterial reproduction, and they should only be used under medical guidance to combat bacterial infections, as they are ineffective against viral infections and can lead to resistance.\n"
     ]
    }
   ],
   "source": [
    "# Text summarization\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": '''\n",
    "    Antibiotics are a type of medication used to treat\n",
    "    bacterial infections. They work by either killing the\n",
    "    bacteria or preventing them from reproducing, allowing\n",
    "    the body’s immune system to fight off the infection.\n",
    "    Antibiotics are usually taken orally in the form of\n",
    "    pills, capsules, or liquid solutions, or sometimes\n",
    "    administered intravenously. They are not effective\n",
    "    against viral infections, and using them inappropriately\n",
    "    can lead to antibiotic resistance.\n",
    "    Explain the above in one sentence:\n",
    "    '''}\n",
    "]\n",
    "\n",
    "response = Lipe(messages, max_new_tokens=1000)  # Adjust the token length as needed\n",
    "print(response[0]['generated_text'][1]['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mice.\n"
     ]
    }
   ],
   "source": [
    "# Question anserwing\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": '''\n",
    "    Answer the question based on the context below. Keep the\n",
    "    answer short and concise. Respond \"Unsure about answer\"\n",
    "    if not sure about the answer.\n",
    "    Context: Teplizumab traces its roots to a New Jersey drug\n",
    "    company called Ortho Pharmaceutical. There, scientists\n",
    "    generated an early version of the antibody, dubbed OKT3.\n",
    "    Originally sourced from mice, the molecule was able to\n",
    "    bind to the surface of T cells and limit their cellkilling\n",
    "    potential. In 1986, it was approved to help\n",
    "    prevent organ rejection after kidney transplants, making\n",
    "    it the first therapeutic antibody allowed for human use.\n",
    "    Question: What was OKT3 originally sourced from?\n",
    "    '''}\n",
    "]\n",
    "\n",
    "response = Lipe(messages, max_new_tokens=1000)  # Adjust the token length as needed\n",
    "print(response[0]['generated_text'][1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would classify the text as neutral. The speaker is expressing a neutral opinion, neither strongly positive nor negative, by saying \"the food was okay\".\n"
     ]
    }
   ],
   "source": [
    "# Classification\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": '''\n",
    "    Classify the text into neutral, negative or positive.\n",
    "    Text: I think the food was okay.    \n",
    "    '''}\n",
    "]\n",
    "\n",
    "response = Lipe(messages, max_new_tokens=1000)  # Adjust the token length as needed\n",
    "print(response[0]['generated_text'][1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human inquiry acknowledged. Creation of black holes involves the collapse of massive, dense stellar remnants under the influence of gravity. This phenomenon occurs when a star with a mass at least 3-4 times that of the sun exhausts its nuclear fuel and undergoes a final, cataclysmic phase of expansion and contraction.\n",
      "\n",
      "The collapse is initiated when the core of the star, comprised primarily of iron and nickel, reaches a temperature of approximately 1.5 million Kelvin. At this point, the core undergoes a rapid expansion, causing the outer layers of the star to be blown off in a supernova explosion. The core, however, continues to collapse under its own gravity, resulting in an increasingly dense and compact object.\n",
      "\n",
      "As the core collapses, the escape velocity from the surface of the object increases, causing any matter that approaches it to be trapped by the object's gravity. This marks the formation of a black hole, characterized by a singularity at its center, where the curvature of spacetime is infinite and the laws of physics as we know them break down.\n",
      "\n",
      "The formation of black holes can occur in various astrophysical contexts, including:\n",
      "\n",
      "1. Stellar collapse: The collapse of individual stars, as described above.\n",
      "2. Binary system mergers: The merger of two compact objects, such as neutron stars or black holes, resulting in a more massive black hole.\n",
      "3. Primordial formation: The formation of black holes from the early universe, through the collapse of gas clouds and the merger of smaller black holes.\n",
      "\n",
      "Black holes are classified into four types, or categories, based on their spin, charge, and mass:\n",
      "\n",
      "1. Schwarzschild black holes: Non-rotating, uncharged black holes with a mass less than 3 times that of the sun.\n",
      "2. Kerr black holes: Rotating black holes with a mass less than 3 times that of the sun.\n",
      "3. Reissner-Nordström black holes: Rotating, charged black holes with a mass less than 3 times that of the sun.\n",
      "4. Kerr-Newman black holes: Rotating, charged black holes with a mass greater than 3 times that of the sun.\n",
      "\n",
      "Understanding the creation and properties of black holes is crucial for advancing our knowledge of astrophysics and the behavior of matter in extreme environments.\n",
      "\n",
      "Would you like to inquire about a specific aspect of black hole physics or explore related topics?\n"
     ]
    }
   ],
   "source": [
    "# Role playing\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": '''\n",
    "    The following is a conversation with an AI research\n",
    "    assistant. The assistant tone is technical and\n",
    "    scientific.\n",
    "    Human: Hello, who are you?\n",
    "    AI: Greeting! I am an AI research assistant. How can I\n",
    "    help you today?\n",
    "    Human: Can you tell me about the creation of blackholes?\n",
    "    '''}\n",
    "]\n",
    "\n",
    "response = Lipe(messages, max_new_tokens=1000)  # Adjust the token length as needed\n",
    "print(response[0]['generated_text'][1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To solve the problem, we'll break it down into steps:\n",
      "\n",
      "Step 1: Identify the odd numbers in the group.\n",
      "The odd numbers in the group are: 15, 5, 13, 7, and 1.\n",
      "\n",
      "Step 2: Add the odd numbers together.\n",
      "15 + 5 = 20\n",
      "20 + 13 = 33\n",
      "33 + 7 = 40\n",
      "40 + 1 = 41\n",
      "\n",
      "Step 3: Determine whether the result is odd or even.\n",
      "The result, 41, is an odd number.\n",
      "\n",
      "Since the sum of the odd numbers (41) is an odd number, we need to continue to find the sum of the even numbers in the group to check if the total sum is even.\n"
     ]
    }
   ],
   "source": [
    "# Reasoning\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": '''\n",
    "    The odd numbers in this group add up to an even number: 15,\n",
    "    32, 5, 13, 82, 7, 1.\n",
    "    Solve by breaking the problem into steps. First, identify\n",
    "    the odd numbers, add them, and indicate whether the result\n",
    "    is odd or even.\n",
    "    '''}\n",
    "]\n",
    "\n",
    "response = Lipe(messages, max_new_tokens=1000)  # Adjust the token length as needed\n",
    "print(response[0]['generated_text'][1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
